{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "colab": {
   "name": "Keras.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ee239c4-5d28-4f67-bfe8-9aba81588c47",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В данной лекции мы с вами научимся пользоваться Keras'ом — частью фреймворка TensorFlow. Keras предназначен для упрощения разработки моделей для решения повседневных задач. В случае исследовательских работ или построения сложных схем лучше делать это на уровне TensorFlow — т.е. пользуясь тензорами, и самостоятельно определяя слои, и как они будут соединяться. Keras же помогает быстро построить модель и обучить ее, используя одну из заранее составленных архитектур или построив простую архитектуру самостоятельно. "
   ],
   "id": "8ee239c4-5d28-4f67-bfe8-9aba81588c47"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbf1dd9f-2f3f-4355-b026-7484275b60e4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В рамках данного курса использования Keras вам будет достаточно для выполнения заданий."
   ],
   "id": "fbf1dd9f-2f3f-4355-b026-7484275b60e4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05f5d9d4-4efe-445c-8946-26a7c0603551",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Для начала проверим, что все необходимые библиотеки установлены. Кроме самого фреймворка, нам с вами еще понадобится пакет tensorflow_datasets для упрощения получения доступа к наборам данных для обучения."
   ],
   "id": "05f5d9d4-4efe-445c-8946-26a7c0603551"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e814da44-dfe5-4267-aff8-ae92b556d4c1",
    "outputId": "76963a23-7cfd-42ce-9222-1ce1a80c7557",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!pip install numpy tensorflow tensorflow_datasets"
   ],
   "id": "e814da44-dfe5-4267-aff8-ae92b556d4c1",
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
      "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.41.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.21.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.62.3)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.4.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.4.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.4)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.16.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (21.2.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5859f83-c4ed-4f6d-b880-c986ffe0433a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Далее импортируем нужные пакеты"
   ],
   "id": "c5859f83-c4ed-4f6d-b880-c986ffe0433a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "21b13862-4cf0-4ce0-b066-538dd2e155a7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds"
   ],
   "id": "21b13862-4cf0-4ce0-b066-538dd2e155a7",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d41fe890-2cd8-42f5-a322-00a0f6deb4fd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Кроме того, давайте посмотрим, где и как в пакете keras расположены необходимые нам элементы.\n",
    "К текущему моменту мы пока что рассмотрили только один тип слоев — полносвязный, однако в дальнейшей в рамках курса мы с вами изучим и другие. Все слои располагаются в модуле layers."
   ],
   "id": "d41fe890-2cd8-42f5-a322-00a0f6deb4fd"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e19dc829-000c-49fe-b7b3-51587691a65a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from tensorflow.keras import layers"
   ],
   "id": "e19dc829-000c-49fe-b7b3-51587691a65a",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "288b4d47-3a24-452d-955a-4947c6eee8b7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Кроме того, мы с вами изучили некоторые функции активации, которые можно использовать при построении ИНС. Все функции активации расположены в пакете activations."
   ],
   "id": "288b4d47-3a24-452d-955a-4947c6eee8b7"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8a56cd51-88b4-4c57-a9ff-16626d27ddf0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from tensorflow.keras import activations"
   ],
   "id": "8a56cd51-88b4-4c57-a9ff-16626d27ddf0",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef5872c7-ee69-42ee-942a-705ab07e16a6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Также импортируем пакет optimizers, в котором расположены оптимизаторы для обучения."
   ],
   "id": "ef5872c7-ee69-42ee-942a-705ab07e16a6"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ea252c09-aa33-4d93-92f9-4ca60f2cf053",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from tensorflow.keras import optimizers"
   ],
   "id": "ea252c09-aa33-4d93-92f9-4ca60f2cf053",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaa2e403-3cf5-412e-9656-2bc5171b4847",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В модуле losses расположены различные функции потерь, которые можно использовать для обучения."
   ],
   "id": "eaa2e403-3cf5-412e-9656-2bc5171b4847"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d92eff25-751b-44db-ae27-2d7ab4cf914e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from tensorflow.keras import losses"
   ],
   "id": "d92eff25-751b-44db-ae27-2d7ab4cf914e",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "426d9b20-c2f2-4964-8840-8546ef29f30a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "И последнее, что нам понадобится импортировать — это метрики из пакета metrics. Функция потерь — это некоторая функция, которая возвращает абстрактный loss, по которому сложно или невозможно оценить качество модели. Для измерения метрик, понятных людям, воспользуемся модулем metrics и заданными там функциями."
   ],
   "id": "426d9b20-c2f2-4964-8840-8546ef29f30a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "878d4eec-d260-422c-9079-098ac2483fb5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from tensorflow.keras import metrics"
   ],
   "id": "878d4eec-d260-422c-9079-098ac2483fb5",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b032d4c-6fc6-42be-a474-ffe9d6205d3c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Пакет tensorflow_datasets содержит код для скачивания открытых наборов данных. Информацию о данном пакете и список доступных наборов данных можно изучить здесь: https://www.tensorflow.org/datasets  \n",
    "\n",
    "Данный пакет нам пригодится для того, чтобы сделать данный ноутбук воспроизводимым и не зависеть от того, правильно ли вы скачаете данные для обучения. В рамках данного урока воспользуемся набором данных <<Ирисы Фишера>>. Это простой набор данных для классификации растений, в котором используется всего 4 признака для определения одного из трех классов растений.\n",
    "\n",
    "Загрузим упомянутый набор данных, разделив на тренировочную и тестовую выборку по границе 80% (т.е. 80% данных будет использоваться для обучения и 20% для валидации модели). Кроме того, в данном случае необходимо указать флаг as_supervised для смены формата выдачи набора данных."
   ],
   "id": "0b032d4c-6fc6-42be-a474-ffe9d6205d3c"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9f2cad0f-11ab-4f3f-9b7a-d5c3c2d12d7d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ds_train, ds_test = tfds.load(\n",
    "    name='iris',\n",
    "    split=['train[:80%]', 'train[80%:]'],\n",
    "    as_supervised=True\n",
    ")"
   ],
   "id": "9f2cad0f-11ab-4f3f-9b7a-d5c3c2d12d7d",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf95814f-0b60-44f4-92b4-746c2c210b59",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Давайте посмотрим на длины полученных тренировочного и валидационного набора данных и проверим, что все в порядке."
   ],
   "id": "bf95814f-0b60-44f4-92b4-746c2c210b59"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d325bf2-e4d6-4378-b853-9ed4a3ef3cb6",
    "outputId": "3a8adfbb-d147-4122-a4ee-c8d098921303",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(f\"Lengths: {len(ds_train)}, {len(ds_test)}\")"
   ],
   "id": "5d325bf2-e4d6-4378-b853-9ed4a3ef3cb6",
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lengths: 120, 30\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fca2f39-638f-4d00-b1bf-483882852e06",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Также давайте возьмем первые 5 записей из тренировочного набора данных и посмотрим на них."
   ],
   "id": "1fca2f39-638f-4d00-b1bf-483882852e06"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53cacb73-d3c5-41a8-a9d2-d294518226b1",
    "outputId": "265b5d5a-0778-4cd5-904c-3eea598b9878",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "examples = ds_train.as_numpy_iterator()\n",
    "examples = [examples.next() for _ in range(5)]\n",
    "features = [i[0] for i in examples]\n",
    "classes = [i[1] for i in examples]\n",
    "\n",
    "print(\"Features \\t\\t Classes\")\n",
    "for i in range(5):\n",
    "    print(f\"{features[i]} \\t {classes[i]}\")"
   ],
   "id": "53cacb73-d3c5-41a8-a9d2-d294518226b1",
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Features \t\t Classes\n",
      "[5.1 3.4 1.5 0.2] \t 0\n",
      "[7.7 3.  6.1 2.3] \t 2\n",
      "[5.7 2.8 4.5 1.3] \t 1\n",
      "[6.8 3.2 5.9 2.3] \t 2\n",
      "[5.2 3.4 1.4 0.2] \t 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "811160ee-908c-4a8b-8e07-2b8fadae05bc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Как можно заметить, данные представлены в следующем формате: у нас имеется 4 признака и одно поле с кодом класса. Классов всего 3. Признаки представлены в удобном для нас формате и мы можем использовать их как есть, а вот класс необходимо преобразовать с помощью one-hot encoding для дальнейшего обучения. Это необходимо нам, т.к. на последнем слое количество выходных нейронов будет равняться числу классов и мы с вами будем выбирать наиболее активировавшийся из них для определения предсказанного класса.  \n",
    "\n",
    "Заведем константы для дальнейшего использования — размер входных данных, размер батча для обучения и количество классов для предсказания."
   ],
   "id": "811160ee-908c-4a8b-8e07-2b8fadae05bc"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6e28337f-2ca5-4c7b-a80c-fb90698528c3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "input_shape = (4, )     # Наши данные - одномерный массив с размерностью 4\n",
    "batch_size = 10         # Размер батча на текущий момент можо выбрать любой, мы рассмотрим его оптимальный выбор далее в рамках курса\n",
    "amount_of_classes = 3   # Количество классов определено данными - 3"
   ],
   "id": "6e28337f-2ca5-4c7b-a80c-fb90698528c3",
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32a63cd0-28fc-4aa7-9ae1-136637227f35",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Далее нам необходимо превратить один столбец с номером класса в 3 столбца, в одном из которых (соответствующему номеру класса) будет стоять единица, а в остальных — нули, т.е. провести процесс one-hot encoding'а. Для этого определим функцию, которую мы хотим применить к набору данных — функцию, которая признаки оставит нетронутыми, а колонку с классом преобразует в необходимый нам формат. Воспользуемся для этого встроенной функцией TensorFlow."
   ],
   "id": "32a63cd0-28fc-4aa7-9ae1-136637227f35"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5343cabc-44fb-4a0d-8523-c8d2433ba0a1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def make_one_hot(x, y):\n",
    "    return x, tf.one_hot(y, depth = amount_of_classes)"
   ],
   "id": "5343cabc-44fb-4a0d-8523-c8d2433ba0a1",
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec006dda-aa35-4974-8826-a47de4f5f3d9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Далее применим к тренировочному набору данных указанное преобразование, а также перемешаем его и нарежем на батчи указанного заранее нами размера. Стоит отметить флаг drop_remainder в конце — при определении батча, данный флаг поможет вам откинуть последний кусок данных, если он не совпадает по размеру с батчем, т.к. данных оказалось недостаточно (т.е. они не делятся нацело на размер батча)."
   ],
   "id": "ec006dda-aa35-4974-8826-a47de4f5f3d9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "550161ab-8689-4b0f-9721-3df535a8ecd2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ds_train = (\n",
    "    ds_train\n",
    "    .map(make_one_hot)\n",
    "    .shuffle(len(ds_train))\n",
    "    .batch(batch_size, drop_remainder = True)\n",
    ")\n",
    "    \n",
    "ds_test = (\n",
    "    ds_test\n",
    "    .map(make_one_hot)\n",
    "    .batch(batch_size, drop_remainder = True)\n",
    ")"
   ],
   "id": "550161ab-8689-4b0f-9721-3df535a8ecd2",
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0964a20-5d76-409c-8ad7-4c176e7ad99c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Далее определим модель. В рамках фреймворка мы с вами будем пользоваться последовательной моделью — т.е. моделью, в которой слои идут последовательно и слой связан только с предыдущим и последующим. Существуют и более сложные архитектуры, мы с вами их рассмотрим позднее.  \n",
    "\n",
    "Создадим последовательную модель и присвоим ее в переменную"
   ],
   "id": "e0964a20-5d76-409c-8ad7-4c176e7ad99c"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8257f3da-43df-40c3-af8d-9365b3d134c5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model = keras.Sequential()"
   ],
   "id": "8257f3da-43df-40c3-af8d-9365b3d134c5",
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7b8d7c8-35f3-46c8-bb9d-706e6678bccc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Далее с помощью функции .add можно добавлять в нее объекты-слои. Фреймворк будет автоматически связывать их с последующими и предыдущими. Первый слой, который мы с вами добавим, это специальный InputLayer объект — слой, определяющий размер входных данных и размер пакета данных."
   ],
   "id": "a7b8d7c8-35f3-46c8-bb9d-706e6678bccc"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8b58099a-51df-4e8e-92e6-488fbc32b7b5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model.add(layers.InputLayer(input_shape = input_shape, batch_size = batch_size))"
   ],
   "id": "8b58099a-51df-4e8e-92e6-488fbc32b7b5",
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b4b022b-39de-4c76-a4b8-d17d611961c1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "После этого можно добавить несколько полносвязных слоев. В каждом слое необходимо указать количество нейронов, а также функцию активации. Функцию активации можно импортировать и указать из пакета activations, которые мы импортировали ранее (заметьте, что я указываю имя функции, а не ее вызов — т.е. не указываю скобки). Также функцию активации можно указать текстовой строкой с названием функции активации (sigmoid, relu, tanh, и т.д.)"
   ],
   "id": "7b4b022b-39de-4c76-a4b8-d17d611961c1"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b28d7839-fe5e-4782-93db-7ad6d3b61f0d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model.add(layers.Dense(32, activation = activations.sigmoid))\n",
    "model.add(layers.Dense(16, activation = 'sigmoid'))"
   ],
   "id": "b28d7839-fe5e-4782-93db-7ad6d3b61f0d",
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d2e826a-d304-4d09-afb0-ebb2a4f98b6c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Последним слоем добавим слой с количеством нейронов равным количеству классов. В качестве функции активации укажем функцию softmax - это функция, реализующая функцию максимума среди всех нейронов слоя, т.е. сумма всех выходов нейронов будет составлять единицу, все выходы будут положительными, и нейрон с самой большей активацией будет иметь наиболее значение в данном промежутке - т.о. вывод данной функции можно рассматривать как приближение вероятности принадлежности экземпляра определенному классу. Данная функция, в отличии от просто функции максимума, является дифференцируемой и может быть использована для обучения методом градиентного спуска."
   ],
   "id": "6d2e826a-d304-4d09-afb0-ebb2a4f98b6c"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a7509442-cbd6-4388-a6d5-8deb079a8694",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model.add(layers.Dense(amount_of_classes, activation = activations.softmax))"
   ],
   "id": "a7509442-cbd6-4388-a6d5-8deb079a8694",
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee6d8dd7-d3dd-4d99-a178-bc9947131a8c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "После определения структуры модели ее необходимо скомпилировать. Этот процесс создает граф вычислений в рамках фреймворка TensorFlow, соответствующий модели и параметрам обучения.  \n",
    "\n",
    "В качестве параметров компиляции необходимо передать экземпляр оптимизатора — создадим для этого новый оптимизатор Adam с коэффициентом скорости обучения 0.003. Кроме того, необходимо задать функцию потерь — т.к. в нашем случае мы решаем задачу многоклассовой классификации, соответствующая функция потерь называется CategoricalCrossentropy. В качестве еще одного аргумента передадим список метрик, которые нам хотелось бы считать в процессе обучения — в данном случае укажем только точность."
   ],
   "id": "ee6d8dd7-d3dd-4d99-a178-bc9947131a8c"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0b47e814-26b1-4f54-931d-a5bade3f217b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model.compile(\n",
    "    optimizer = optimizers.Adam(learning_rate = 0.003),\n",
    "    loss = losses.CategoricalCrossentropy(),\n",
    "    metrics = [metrics.CategoricalAccuracy()]\n",
    ")"
   ],
   "id": "0b47e814-26b1-4f54-931d-a5bade3f217b",
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c71142c4-c491-425d-9c64-4eaea8fed17a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Процесс обучения модели запускается с помощью функции fit. В данную функцию мы подадим сам набор данных для обучения, количество эпох и набор валидационных данных. Функция запустит и обучит модель и вернет результаты в виде объекта keras.History."
   ],
   "id": "c71142c4-c491-425d-9c64-4eaea8fed17a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "20335f69-c9bf-4d72-b41a-762dcd9b49f3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8c597123-6717-4dec-d24b-93d7b032998f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "history = model.fit(ds_train, epochs = 20, validation_data = ds_test)"
   ],
   "id": "20335f69-c9bf-4d72-b41a-762dcd9b49f3",
   "execution_count": 46,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - 1s 23ms/step - loss: 1.1161 - categorical_accuracy: 0.2833 - val_loss: 1.0982 - val_categorical_accuracy: 0.3000\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0988 - categorical_accuracy: 0.3083 - val_loss: 1.0942 - val_categorical_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0994 - categorical_accuracy: 0.3583 - val_loss: 1.0944 - val_categorical_accuracy: 0.3000\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0866 - categorical_accuracy: 0.4333 - val_loss: 1.0816 - val_categorical_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0799 - categorical_accuracy: 0.5917 - val_loss: 1.0680 - val_categorical_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0569 - categorical_accuracy: 0.6500 - val_loss: 1.0463 - val_categorical_accuracy: 0.6333\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0190 - categorical_accuracy: 0.6750 - val_loss: 0.9964 - val_categorical_accuracy: 0.6333\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.9483 - categorical_accuracy: 0.7250 - val_loss: 0.9102 - val_categorical_accuracy: 0.7000\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8429 - categorical_accuracy: 0.8333 - val_loss: 0.7954 - val_categorical_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7253 - categorical_accuracy: 0.6833 - val_loss: 0.6876 - val_categorical_accuracy: 0.7000\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6299 - categorical_accuracy: 0.7083 - val_loss: 0.6134 - val_categorical_accuracy: 0.7000\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5660 - categorical_accuracy: 0.6917 - val_loss: 0.5725 - val_categorical_accuracy: 0.6333\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5320 - categorical_accuracy: 0.6917 - val_loss: 0.5427 - val_categorical_accuracy: 0.7333\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5059 - categorical_accuracy: 0.8000 - val_loss: 0.5179 - val_categorical_accuracy: 0.8667\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4846 - categorical_accuracy: 0.8417 - val_loss: 0.4975 - val_categorical_accuracy: 0.8333\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4631 - categorical_accuracy: 0.9083 - val_loss: 0.4715 - val_categorical_accuracy: 0.8667\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4293 - categorical_accuracy: 0.9500 - val_loss: 0.4511 - val_categorical_accuracy: 0.9667\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4018 - categorical_accuracy: 0.9500 - val_loss: 0.4202 - val_categorical_accuracy: 0.8667\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3625 - categorical_accuracy: 0.9333 - val_loss: 0.3887 - val_categorical_accuracy: 0.9333\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3316 - categorical_accuracy: 0.9250 - val_loss: 0.3547 - val_categorical_accuracy: 0.9000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c719ce5a-0e4c-45d5-87cb-0a61ec84e95d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Данный объект (keras.History) содержит в себе историю процесса обучения, использованные параметры и ссылки на модель и объекты, использованные в процессе обучения. К примеру, можно вывести параметры обучения:"
   ],
   "id": "c719ce5a-0e4c-45d5-87cb-0a61ec84e95d"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "efde3789-cc7c-44bd-b927-5d013ed70cdb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "149e321b-387d-49f0-c17a-302d6296a40d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(f\"Params of training: {history.params}\")"
   ],
   "id": "efde3789-cc7c-44bd-b927-5d013ed70cdb",
   "execution_count": 47,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Params of training: {'verbose': 1, 'epochs': 20, 'steps': 12}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0d9f5af-693c-407a-b34f-8633fae0f574",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Также можно узнать, какой коэффициент скорости обучения использовался:"
   ],
   "id": "d0d9f5af-693c-407a-b34f-8633fae0f574"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "527ee596-7de8-49a2-9c0a-858387375800",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8e6db00f-6406-4ccd-ebf0-3dbd7257f250",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(f\"Used learning rate: {history.model.optimizer.lr}\")"
   ],
   "id": "527ee596-7de8-49a2-9c0a-858387375800",
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Used learning rate: <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.003>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f04e2e35-dc54-492c-a83d-6ec2a62f9862",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Или даже посмотреть на веса обученного первого слоя модели:"
   ],
   "id": "f04e2e35-dc54-492c-a83d-6ec2a62f9862"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1a86ece2-46ac-4d68-beab-f118707e0919",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4796cf6e-e6f0-402e-e082-97cdbf878126",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(f\"Weights of first layer: {history.model.layers[0].weights}\")"
   ],
   "id": "1a86ece2-46ac-4d68-beab-f118707e0919",
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weights of first layer: [<tf.Variable 'dense/kernel:0' shape=(4, 32) dtype=float32, numpy=\n",
      "array([[-6.7500181e-02,  8.0909930e-02,  1.6028395e-01,  2.8937433e-02,\n",
      "         3.4164953e-01, -1.7730370e-01, -3.3788927e-02, -1.2303364e-01,\n",
      "        -3.3968163e-01,  3.4202796e-01, -1.0304890e-01,  9.1854535e-02,\n",
      "         2.0038342e-01, -3.7304717e-01,  4.3325476e-02, -5.1417588e-03,\n",
      "         5.0077688e-02, -8.2647406e-02,  4.7157648e-01, -9.5600381e-02,\n",
      "        -2.7143443e-01,  3.4877896e-01,  2.9560718e-01,  3.8874272e-01,\n",
      "        -2.2991458e-01,  2.0062187e-01, -3.4853894e-01, -1.7595150e-01,\n",
      "         3.8466939e-01, -4.2015116e-04,  9.1322176e-02,  3.9582682e-01],\n",
      "       [-5.1679927e-01,  4.5140556e-01,  1.4167824e-01, -4.9091393e-01,\n",
      "         1.5929000e-01, -4.3265921e-01,  5.7061356e-01, -5.9294182e-01,\n",
      "        -1.0531675e-02,  1.6056763e-01,  6.2048244e-01,  2.8663203e-01,\n",
      "        -1.1149230e-03,  4.8466739e-01,  5.0815195e-01,  8.0178010e-01,\n",
      "        -3.7230083e-01, -6.2644951e-02,  2.2057936e-01, -5.0484955e-01,\n",
      "        -4.1384977e-01,  1.3779463e-01, -4.9450946e-01,  2.7773997e-01,\n",
      "        -3.5286474e-01, -6.0473406e-01, -4.5182449e-01, -6.0744113e-01,\n",
      "         5.0129730e-01, -6.4920783e-01,  6.5203071e-01,  2.6509574e-01],\n",
      "       [ 5.2925640e-01, -4.1831520e-01, -5.2282643e-01,  4.2068622e-01,\n",
      "        -6.6908103e-01,  7.4732989e-01, -4.3135327e-01,  6.9949424e-01,\n",
      "         5.5588979e-01, -4.9254957e-01, -4.0849602e-01, -2.8151360e-01,\n",
      "        -3.6154193e-01,  5.1764213e-03, -3.3242443e-01, -5.0806522e-01,\n",
      "         1.9189563e-01, -1.5337923e-01, -6.1354584e-01,  4.0466288e-01,\n",
      "         6.5241188e-01, -6.5164423e-01,  1.5416604e-01, -7.1542978e-01,\n",
      "         4.7229230e-01,  2.4998310e-01,  6.9246268e-01,  7.6358068e-01,\n",
      "         3.7701204e-02,  4.5445919e-01, -6.4943898e-01, -6.5565151e-01],\n",
      "       [ 4.5437169e-01, -6.3079166e-01, -3.8158143e-01,  3.2527275e-02,\n",
      "        -1.7500834e-01,  2.8047299e-01, -4.2039320e-01,  3.0820096e-01,\n",
      "         5.4653221e-01, -4.5097324e-01, -6.8665373e-01, -4.6024710e-01,\n",
      "        -4.3038365e-01, -4.6665967e-01, -7.1287197e-01, -6.0062695e-01,\n",
      "         4.0823022e-01, -5.2246666e-01, -8.2892627e-01,  5.8432734e-01,\n",
      "         4.4119784e-01, -1.2749228e-01,  4.0730691e-01, -5.7799333e-01,\n",
      "         7.1677238e-01,  6.5785974e-01,  7.6836246e-01,  3.3038715e-01,\n",
      "         3.1680923e-02,  5.0784940e-01, -7.3701912e-01, -5.3299886e-01]],\n",
      "      dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([-0.31825128, -0.04888014,  0.37530074, -0.25697765,  0.37977225,\n",
      "       -0.07137514,  0.4034728 , -0.1593374 , -0.16541907,  0.08394422,\n",
      "        0.29661846,  0.01014279,  0.2400365 ,  0.01165296,  0.4249923 ,\n",
      "        0.41322625, -0.32235953,  0.11628368,  0.21020648, -0.26419297,\n",
      "        0.01859596,  0.22536056, -0.22014737,  0.26224658, -0.32034248,\n",
      "       -0.1346977 , -0.09254695, -0.1400354 ,  0.19533692, -0.35830945,\n",
      "        0.29257435,  0.3743318 ], dtype=float32)>]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efbf3143-1c9f-42a4-bd5c-851dd65319e3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Далее обученную модель можно сериализовать с помощью средств фреймворка или использовать для предсказания на существующем сформированном наборе данных. Результатом предсказания будут значения трех нейронов классов, соответствующие вероятностям принадлежности экземпляра соответствующему классу."
   ],
   "id": "efbf3143-1c9f-42a4-bd5c-851dd65319e3"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f62455d7-6049-41f2-8799-a3f3f4837022",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b3c9e18a-334d-4184-cda0-8c459e4e8722",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model.predict(ds_test)"
   ],
   "id": "f62455d7-6049-41f2-8799-a3f3f4837022",
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.9073463 , 0.07663125, 0.01602243],\n",
       "       [0.9068328 , 0.07707343, 0.01609371],\n",
       "       [0.00559126, 0.2246644 , 0.7697443 ],\n",
       "       [0.9079279 , 0.07613076, 0.01594133],\n",
       "       [0.00899539, 0.3098335 , 0.6811712 ],\n",
       "       [0.00652572, 0.25007355, 0.7434007 ],\n",
       "       [0.9045819 , 0.07901147, 0.01640665],\n",
       "       [0.00744433, 0.2734622 , 0.7190935 ],\n",
       "       [0.00660211, 0.25214058, 0.74125737],\n",
       "       [0.00809676, 0.28933084, 0.70257235],\n",
       "       [0.01338509, 0.3962933 , 0.5903216 ],\n",
       "       [0.03343655, 0.6145688 , 0.3519946 ],\n",
       "       [0.01262732, 0.38322127, 0.6041514 ],\n",
       "       [0.9061336 , 0.07767531, 0.01619107],\n",
       "       [0.13046868, 0.7264381 , 0.14309318],\n",
       "       [0.04946885, 0.68643516, 0.26409593],\n",
       "       [0.02033362, 0.49784508, 0.4818213 ],\n",
       "       [0.01090373, 0.35026565, 0.6388306 ],\n",
       "       [0.90698   , 0.07694661, 0.01607342],\n",
       "       [0.00899735, 0.30982357, 0.6811791 ],\n",
       "       [0.03642375, 0.63231266, 0.33126357],\n",
       "       [0.00757621, 0.27678543, 0.71563834],\n",
       "       [0.05378161, 0.697057  , 0.24916135],\n",
       "       [0.90777147, 0.07626548, 0.01596313],\n",
       "       [0.00740287, 0.27238235, 0.7202148 ],\n",
       "       [0.9092028 , 0.07503361, 0.01576357],\n",
       "       [0.14564194, 0.7190198 , 0.13533828],\n",
       "       [0.00660138, 0.25206923, 0.7413294 ],\n",
       "       [0.05964567, 0.7087997 , 0.2315546 ],\n",
       "       [0.9068328 , 0.07707343, 0.01609371]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ]
  }
 ]
}