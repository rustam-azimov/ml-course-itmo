{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c510bf9b-2c8d-43e1-af0d-6040b7d9948b",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6\n",
    "\n",
    "- **Дедлайн**: 04.06.2023, 23:59\n",
    "- **Максимум баллов**: 10\n",
    "\n",
    "В рамках данной работы мы с вами будем реализовывать нейронную сеть с помощью библиотеки numpy.  \n",
    "\n",
    "В данном ноутбуке вы найдете почти готовую к применению нейронную сеть, созданную для решения конкретной задачи на конкретном наборе данных. В некоторых местах данного ноутбука код пропущен и вместо него стоит заглушка \"\\<ENTER YOUR CODE HERE>\". Это означает, что вместо этой заглушки вам необходимо написать собственный код, решающий какую-то конкретную подзадачу. Детали вы найдете в комментариях около каждого из таких мест.  \n",
    "\n",
    "Давайте проверим, что у нас установлены все необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd098512-cee5-4cd6-aa57-e175d927f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy matplotlib \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239fa00d-47f5-4fa7-8d09-8ae14760b5d8",
   "metadata": {},
   "source": [
    "В данной лабораторной работе мы будем использовать достаточно простой набор данных. Этот набор будет состоять из 4-х экземпляров одного из двух классов, таким образом, решаемая нами задача - бинарная классификация.  \n",
    "\n",
    "Сгенерируем данные самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24e131-f75d-4ad9-bc89-5208a3c658b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "    0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
    "    0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
    "    0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
    "    0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "    0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
    "    0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "    1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
    "    0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "    0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
    "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "]).reshape(1, -1)\n",
    "\n",
    "b = np.array([\n",
    "    1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "    1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
    "    1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
    "    1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
    "    1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    "    1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
    "    1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
    "    0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "    0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
    "    0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
    "]).reshape(1, -1)\n",
    "\n",
    "c = np.array([\n",
    "    0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
    "    0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
    "    0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
    "    0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "    0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
    "    0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "    0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
    "    0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
    "    0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "    0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
    "]).reshape(1, -1)\n",
    "\n",
    "d = np.array([\n",
    "    0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
    "    0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
    "    0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
    "    0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
    "    0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
    "    0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
    "    0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
    "    0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
    "    0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
    "    0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
    "]).reshape(1, -1)\n",
    "\n",
    "# Набор векторов признаков для каждого из 4-х экземпляров\n",
    "x = [a, b, c, d]\n",
    "\n",
    "# Метки классов для каждого из 4-х экземпляров\n",
    "y = np.array([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eacb3a-4e42-4132-a9c4-d96f3bc13385",
   "metadata": {},
   "source": [
    "Давайте визуализируем данные и проверим визуально, что классы легко различимы и сеть сможет с ними справиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08686c3-cf34-4783-a1ea-1469e812e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "f, axarr = plt.subplots(1, 4)\n",
    "axarr[0].imshow(a[0].reshape(10, 10))\n",
    "axarr[0].set_title('Котик')\n",
    "\n",
    "axarr[1].imshow(b[0].reshape(10, 10))\n",
    "axarr[1].set_title('Котик')\n",
    "\n",
    "axarr[2].imshow(c[0].reshape(10, 10))\n",
    "axarr[2].set_title('Домик')\n",
    "\n",
    "axarr[3].imshow(d[0].reshape(10, 10))\n",
    "axarr[3].set_title('Домик')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac110e4-8ce6-4f7b-bb1c-8e831d08e566",
   "metadata": {},
   "source": [
    "Итак, внимательно изучив предлагаемый набор данных, давайте подумаем о структуре нашей сети и ее \"строительных элементах\" - частях, из которых она будет состоять. Мы будем реализовывать эти части по очереди, проверяя, что они работают корректно, а затем использовать в последующих функциях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b52e23-ef18-4f27-bfaa-0a8c367f6f6f",
   "metadata": {},
   "source": [
    "Наш набор данных состоит из одномерного вектора длиной 100 элементов, следовательно размер входного слоя должен составлять 100 элементов. Нашей задачей является бинарная классификация объектов, где метка 0 обозначает котиков, а метка 1 - домики. Соответственно, на выходе нашей сети должен присутствовать только один нейрон, который будет выдавать значения от 0 до 1 - т.е. функцией нелинейности должна быть сигмоида.\n",
    "\n",
    "Кроме того, мы будем использовать сигмоиду в качестве функции активации между слоями нашей сети, поэтому давайте реализуем ее в первую очередь. Напомним, что сигмоида выглядит следующим образом: $sigmoid(x)=\\dfrac{1}{1+\\exp(-x)}$. Кроме того, рекомендуем вам вспомнить, как выглядит градиент сигмоиды, т.к. его нам тоже необходимо реализовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60bdf3-63c1-4b69-9013-195c27021b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуйте функцию сигмоиду, ...\n",
    "def sigmoid(x):\n",
    "    \"<ENTER YOUR CODE HERE>\"\n",
    "    return 0\n",
    "\n",
    "# ...а также ее градиент\n",
    "def sigmoid_grad(x):\n",
    "    \"<ENTER YOUR CODE HERE>\"\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987b797-dede-41ad-9ba0-252c1731a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тесты предназначены для проверки того, что вы корректно реализовали функцию\n",
    "assert np.isclose(sigmoid(0), 0.5)\n",
    "assert np.isclose(sigmoid(1), 0.7310585786300049)\n",
    "\n",
    "assert np.isclose(sigmoid_grad(0), 0.25)\n",
    "assert np.isclose(sigmoid_grad(1), 0.19661193324148185)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a693e9-685e-410e-9a3e-5ed211f2685d",
   "metadata": {},
   "source": [
    "Кроме функции активации нам понадобится функция генерации полносвязного слоя нейронов. Данная функция должна сгенерировать слой необходимого размера, заполнив его случайными значениями. Мы рекомендуем использовать для этого нормальное распределение с средним значением 0 и дисперсией 1.\n",
    "\n",
    "Реализуйте функцию generate_layer(x, y), которая по заданным x и y (входному числу параметров и выходному числу параметров) будет генерировать случайный массив данных размера (x, y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d432d-366c-42ec-ab3a-623dce058fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_layer(x, y):\n",
    "    return \"<ENTER YOUR CODE HERE>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b959490-5bb8-4731-bcfb-816001bc30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный тест проверяет вашу реализацию\n",
    "assert generate_layer(5, 7).shape == (5, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87376ef0-fe7d-4c6e-b588-3a3abc3a2828",
   "metadata": {},
   "source": [
    "Далее давайте реализуем функцию ошибки для бинарной классификации. Из предыдущих курсов вы должны помнить, то подходящей функций ошибки в данном случае является функция бинарной кроссэнтропии. Давайте также реализуем ее отдельной функцией. Напомним, что в случае единственного экземпляра данных (а мы сейчас хотим реализовать ее для единственного экземпляра) ее функция будет выглядеть следующим образом:\n",
    "$$crossentropy(y, \\hat y) = - (y * log(\\hat y) + (1-y)*log(1-\\hat y))$$,\n",
    "где $y$ - это правильное значение класса, а $\\hat y$ - предсказанное моделью значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e291cf-ff71-416f-95ee-2cc5e7d5b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(predicted, ground_truth):\n",
    "    # binary crossentropy loss\n",
    "    return \"<ENTER YOUR CODE HERE>\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6909da-af4b-4d3c-bdf2-33bc2ab2da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(loss(0.5, 0), 0.6931471805599453)\n",
    "assert np.isclose(loss(0.1, 1), 2.3025850929940455)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb1dc0-0ab3-49fb-a076-66855008f2ba",
   "metadata": {},
   "source": [
    "Итак, к настоящему моменту мы создали необходимые функции активации, потерь и генерации слоев. Теперь пришла пора переходить к созданию самой сети и ее функций.  \n",
    "\n",
    "Для данного набора данных мы с вами будем использовать нейронную сеть состоящую из двух слоев. Первый слой будет состоять из 32-х нейронов, а второй - из одного нейрона и являться выходным слоем. Для упрощения вычислений будем использовать нейронный слой с весами, но без смещений. \n",
    "\n",
    "Давайте напишем функцию forward_pass, которая будет совершать прямой проход по нейронной сети и применять функции активации, а также возвращать два объекта:\n",
    " 1. значения всех вычислений после применения функции активации\n",
    " 2. кортеж всех промежуточных значений, полученных в процессе вычислений, чтобы мы могли использовать их для подсчета градиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce098b61-131f-4d01-bb40-71b3fb42ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(data, weights_layer1, weights_layer2):\n",
    "    # Предполагаем, что weights_layer1 и weights_layer2 - массивы весов корректных размеров\n",
    "    \n",
    "    # Пропустим данные через первый слой \n",
    "    # в матричном случае это означает матричное умножение данных на веса\n",
    "    output1 = \"<ENTER YOUR CODE HERE>\"\n",
    "    \n",
    "    # Далее применим функцию активации к полученным данным\n",
    "    activation1 = \"<ENTER YOUR CODE HERE>\"\n",
    "     \n",
    "    # Далее пропустим аналогичным образом данные через второй слой\n",
    "    output2 = \"<ENTER YOUR CODE HERE>\"\n",
    "    \n",
    "    # И снова применим функцию активации\n",
    "    activation2 = \"<ENTER YOUR CODE HERE>\"\n",
    "    \n",
    "    # вернем полученный результат и \n",
    "    result = activation2\n",
    "    return result, (output1, activation1, output2, activation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466f29a-8655-485a-8711-fc4a1e70836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(data, weights_layer1, weights_layer2):\n",
    "    output1 = data.dot(weights_layer1)\n",
    "    activation1 = sigmoid(output1)\n",
    "     \n",
    "    output2 = activation1.dot(weights_layer2)\n",
    "    activation2 = sigmoid(output2)\n",
    "    \n",
    "    result = activation2\n",
    "    return result, (output1, activation1, output2, activation2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f52510-eadf-4568-b915-d80f93616cd1",
   "metadata": {},
   "source": [
    "Далее начинается сложная часть. Нам необходимо реализовать функцию обратного распространения ошибки. Данная функция будет принимать вектор X, правильный класс y, веса слоев 1 и 2 нейронной сети, а также learning rate - значение от 0 до 1, на которое будут домножаться градиенты для ограничения скорости градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11eb748-47d7-4329-8404-90a529f052b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(x, y, weights_layer1, weights_layer2, learning_rate):\n",
    "    # Давайте получим результат прямого прохода по нашей нейронной сети\n",
    "    result, (output1, activation1, output2, activation2) = forward_pass(x, weights_layer1, weights_layer2) \n",
    "\n",
    "    # Далее посчитаем ошибку в каждом слое\n",
    "    # ошибка в первом слое равна разнице между результатом и истинным значением\n",
    "    d2 = \"<ENTER YOUR CODE HERE>\"\n",
    "    \n",
    "    # Ошибка во втором слое считается чуть сложнее, поэтому мы реализовали ее за вас\n",
    "    d1 = weights_layer2.dot(d2.T).T * sigmoid_grad(activation1)\n",
    " \n",
    "    # Далее считаем градиенты для каждого из слоев\n",
    "    w1_adj = x.T.dot(d1)            # градиент для первого слоя\n",
    "    w2_adj = activation1.T.dot(d2)  # градиент для второго слоя\n",
    "    \n",
    "    # И давайте вычтем посчитанные градиенты из каждого из слоев, не забыв домножить их на learning_rate\n",
    "    weights_layer1 = \"<ENTER YOUR CODE HERE>\"\n",
    "    weights_layer2 = \"<ENTER YOUR CODE HERE>\"\n",
    "    \n",
    "    # После этого вернем новые значения весов для обоих слоев нейронной сети\n",
    "    return weights_layer1, weights_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bac25-fc17-4d7a-9b6f-03b309421b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(x, y, weights_layer1, weights_layer2, learning_rate):\n",
    "    result, (output1, activation1, output2, activation2) = forward_pass(x, weights_layer1, weights_layer2) \n",
    "\n",
    "    d2 = (activation2 - y)\n",
    "    d1 = weights_layer2.dot(d2.T).T * sigmoid_grad(activation1)\n",
    " \n",
    "\n",
    "    w1_adj = x.T.dot(d1)\n",
    "    w2_adj = activation1.T.dot(d2)\n",
    "     \n",
    "\n",
    "    weights_layer1 = weights_layer1 - learning_rate * w1_adj\n",
    "    weights_layer2 = weights_layer2 - learning_rate * w2_adj\n",
    "     \n",
    "    return weights_layer1, weights_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0567c8cb-15e5-4212-a667-eaee27d6fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тесты для проверки функции back_propagation\n",
    "test_x = np.array([0.5, 0.1, 0.2, 0.3]).reshape(2, 2)\n",
    "test_y = np.array([0])\n",
    "test_w1 = np.array([0.11, 0.12, 0.13, -0.31, 0.44, -0.2]).reshape(2, 3)\n",
    "test_w2 = np.array([0.33, -0.1, 0.95]).reshape(3, 1)\n",
    "\n",
    "new_test_w1, new_test_w2 = back_propagation(test_x, test_y, test_w1, test_w2, 0.1)\n",
    "assert new_test_w1.shape == test_w1.shape\n",
    "assert new_test_w2.shape == test_w2.shape\n",
    "assert np.allclose(new_test_w1, np.array([0.1065043, 0.12105125, 0.11995235, -0.31199363, 0.440597, -0.20572788]).reshape(2, 3))\n",
    "assert np.allclose(new_test_w2, np.array([0.26649996, -0.16841221, 0.88557019]).reshape(3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02de22d-a617-4240-9d99-4a3b60095323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, weights_layer1, weights_layer2, learning_rate = 0.01, epochs = 10):\n",
    "    dataset_size = len(X)\n",
    "    \n",
    "    # Создаем переменные для сохранения истории метрики и функции потерь\n",
    "    accuracy_history = []\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0      # лосс текущей эпохи    \n",
    "        correct_amount = 0  # количество верно классифицированных элементов\n",
    "        \n",
    "        # перемешаем набор данных\n",
    "        random.shuffle(X)\n",
    "        \n",
    "        # будем последовательно брать каждый элемент \n",
    "        for i in range(dataset_size):\n",
    "            # Совершаем прямой проход, подавая i-й элемент массива признаков  \n",
    "            out, _ = \"<ENTER YOUR CODE HERE>\"\n",
    "            \n",
    "            # Добавляем значение функции потерь\n",
    "            epoch_loss += np.squeeze(loss(out, y[i]))\n",
    "            \n",
    "            # Проверяем, классифицирован ли объект верно (т.е. оценка ближе к верному классу, чем к неверному)\n",
    "            correct_amount += int(abs(np.squeeze(out) - y[i]) < 0.5)\n",
    "            \n",
    "            # Осуществляем градиентный спуск, используя i-й элемент массива признаков и классов \n",
    "            weights_layer1, weights_layer2 = \"<ENTER YOUR CODE HERE>\"\n",
    "            \n",
    "        # Вычисляем точность на текущей эпохи и сохраняем данные\n",
    "        accuracy = correct_amount / dataset_size\n",
    "        accuracy_history.append(accuracy)\n",
    "        loss_history.append(epoch_loss)\n",
    "        print(f\"Epoch: {epoch + 1}/{epochs}, \\t ======== accuracy: {accuracy}, loss: {epoch_loss}\")\n",
    "\n",
    "    return accuracy_history, loss_history, (weights_layer1, weights_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17525bd7-4886-4a6a-b5b2-222b896f6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тест для проверки функции train\n",
    "test_x = [np.array([0.2, 0.3]).reshape(1, 2)]\n",
    "test_y = [np.array([0])]\n",
    "test_w1 = np.array([0.11, 0.12, 0.13, -0.31, 0.44, -0.2]).reshape(2, 3)\n",
    "test_w2 = np.array([0.33, -0.1, 0.95]).reshape(3, 1)\n",
    "\n",
    "test_acc_h, test_l_h, (new_test_w1, new_test_w2) = train(test_x, test_y, test_w1, test_w2, 1, 1)\n",
    "assert len(test_acc_h) == len(test_l_h) == 1\n",
    "assert np.isclose(test_acc_h[0], 0.0)\n",
    "assert np.isclose(test_l_h[0], 1.0196136855432536)\n",
    "assert test_w1.shape == new_test_w1.shape\n",
    "assert test_w2.shape == new_test_w2.shape\n",
    "assert np.allclose(new_test_w1, np.array([[0.10004239, 0.12297504, 0.10139734], [-0.32493642, 0.44446255, -0.24290399]]))\n",
    "assert np.allclose(new_test_w2, np.array([[0.02170934], [-0.44451379], [0.63580037]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf966c6-d246-44f0-90d4-48f8d6f28087",
   "metadata": {},
   "source": [
    "Итак, настало время создать нашу нейронную сеть и обучить ее на нашем наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36efe3df-12e1-4803-8ced-719b78f5a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим слои нейронной сети с нужным количеством параметров\n",
    "layer1 = generate_layer(100, 32)  # в первом слое - 32 нейрона\n",
    "layer2 = generate_layer(32, 1)    # в втором слое - 1 нейрон\n",
    "\n",
    "# зададим learning rate и количество эпох\n",
    "learning_rate = 0.1\n",
    "epochs = 10\n",
    "\n",
    "# и запустим процесс обучения\n",
    "accuracy_history, loss_history, (layer1, layer2) = train(x, y, layer1, layer2, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae625f9-7f53-4809-88cc-06d02ebf8c2c",
   "metadata": {},
   "source": [
    "Давайте визуализируем полученные графики точности и функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e59333-bb41-4a71-af94-470224151478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изменим размер изображения в jupyter notebook\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "\n",
    "plt.figure()\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].plot(accuracy_history)\n",
    "axarr[0].set_ylabel('Accuracy')\n",
    "axarr[0].set_xlabel(\"Epochs:\")\n",
    "\n",
    "axarr[1].plot(loss_history)\n",
    "axarr[1].set_ylabel('Loss')\n",
    "axarr[1].set_xlabel(\"Epochs:\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9267295b-d293-4dce-a1d8-b4d26572f951",
   "metadata": {},
   "source": [
    "Для визуальной оценки набора данных давайте отобразим предсказание сети для каждого из элементов массива признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098dfdab-a7c2-410b-8532-b80032359c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, weights_layer1, weights_layer2):\n",
    "    plt.figure()\n",
    "    fig, axarr = plt.subplots(1, len(x))\n",
    "    \n",
    "    for i, v in enumerate(x):\n",
    "        out, _ = forward_pass(v, weights_layer1, weights_layer2)\n",
    "        label = \"Домик\" if out[0][0] > 0.5 else \"Котик\"\n",
    "        axarr[i].imshow(v.reshape(10, 10))\n",
    "        axarr[i].set_title(label)\n",
    "        \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2328e0c-6d1d-4827-9ed9-4da627186290",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(x, layer1, layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f06db1-147a-4646-a5fc-5468c3dce14a",
   "metadata": {},
   "source": [
    "Итак, мы надеемся, что у вас успешно получилось реализовать простую нейронную сеть с помощью библиотеки NumPy и наших подсказок в процессе разработки, и натренировать ее для успешного распознавания котиков и домиков. :)\n",
    "\n",
    "К счастью, вам вряд ли еще раз придется это делать. К настоящему времени в мире разработано достаточно много фреймворков глубокого обучения, позволяющих автоматизировать и упростить все вышепроделанные операции. О них речь пойдет в следующей главе.\n",
    "\n",
    "Успехов!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
